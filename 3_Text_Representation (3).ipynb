{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "3_Text_Representation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XnMsYYNwvz_"
      },
      "source": [
        "# Exercise 3. Text Representation Part 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dp1ey_v2wv0G"
      },
      "source": [
        "In this exercise we will derive the document representation of the preprocessed (stemmed) newsgroups dataset. We will apply sklearn as well as gensim to derive the Bag-of-words document representation. Those two packages are the standard packages for deriving the  Bag-of-words document representation.\n",
        "\n",
        "We will calculate the following representations for each package:\n",
        "\n",
        "* Absolute frequencies\n",
        "* Relative frequencies\n",
        "* TF-IDF frequences\n",
        "\n",
        "Finally, we will derive N-grams for the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8gu7Lecwv0H"
      },
      "source": [
        "# Import packages\n",
        "import pickle\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.preprocessing import Binarizer\n",
        "import pandas as pd\n",
        "from gensim.corpora import Dictionary\n",
        "from gensim.models import TfidfModel\n",
        "import math"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LhhBRqVhw1Td",
        "outputId": "f34844d7-3504-4f01-8b41-d7e30b19f015"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eB-mNgHZwv0H",
        "outputId": "6bfab2d9-2fc7-43ea-ad2d-2d4515d873f4"
      },
      "source": [
        "# Import dataset\n",
        "data_stem=pickle.load(open(\"/content/drive/MyDrive/TWSM_Data/Stemmed.pkl\", \"rb\"))\n",
        "print(data_stem[0])\n",
        "print(' ')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "car wonder enlighten car saw dai door sport car look late earli call bricklin door small addit bumper separ rest bodi know tellm model engin spec year product car histori info funki look car mail thank\n",
            " \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "enSQRST2wv0J",
        "outputId": "6be0b31a-03e5-49e7-9b99-c994e604e2b7"
      },
      "source": [
        "len(data_stem)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11314"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "synNUO1Wwv0J"
      },
      "source": [
        "# 1. Bag-of-words with sklearn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Szs-FHi0wv0J"
      },
      "source": [
        "Apply the sklearn tranformations by removing all words that appear in less than min_df of the documents and more than max_df of the documents."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQrZuKL8wv0K"
      },
      "source": [
        "# Set transformers\n",
        "vec_bin=Binarizer() # One-hot\n",
        "vec_abs= CountVectorizer(max_df=0.95, min_df=0.05) #Absolute frequency\n",
        "vec_rel = TfidfVectorizer(max_df=0.95, min_df=0.05, use_idf=False, norm='l1') # Relative frequency\n",
        "vec_tf=TfidfVectorizer(max_df=0.95, min_df=0.05, smooth_idf=False) #Tf-IDF frequency\n",
        "\n",
        "# Tranform stemmed data\n",
        "corpus_sk_abs=vec_abs.fit_transform(data_stem)\n",
        "corpus_sk_bin=vec_bin.fit_transform(corpus_sk_abs)\n",
        "corpus_sk_rel=vec_rel.fit_transform(data_stem)\n",
        "corpus_sk_tf=vec_tf.fit_transform(data_stem)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0qWBzn2wv0K"
      },
      "source": [
        "Show words in dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAndFfMmwv0K",
        "outputId": "03e30adb-9468-4e99-8f6e-1885736c3f80"
      },
      "source": [
        "print('The number of features is: ',len(vec_tf.get_feature_names()))\n",
        "print('')\n",
        "print(vec_tf.get_feature_names())\n",
        "print(vec_abs.get_feature_names())\n",
        "print(vec_rel.get_feature_names())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The number of features is:  240\n",
            "\n",
            "['abl', 'accept', 'actual', 'address', 'advanc', 'ago', 'agre', 'allow', 'american', 'answer', 'anybodi', 'appreci', 'apr', 'area', 'articl', 'ask', 'assum', 'avail', 'awai', 'bad', 'base', 'believ', 'best', 'better', 'big', 'bit', 'book', 'bui', 'call', 'car', 'card', 'care', 'case', 'caus', 'chang', 'check', 'chip', 'christian', 'claim', 'close', 'com', 'come', 'complet', 'consid', 'control', 'correct', 'cost', 'cours', 'current', 'dai', 'data', 'david', 'deal', 'design', 'differ', 'discuss', 'drive', 'edu', 'effect', 'email', 'end', 'engin', 'exampl', 'exist', 'expect', 'experi', 'fact', 'far', 'fax', 'feel', 'file', 'final', 'follow', 'forc', 'free', 'game', 'gener', 'get', 'given', 'go', 'god', 'good', 'got', 'govern', 'great', 'group', 'guess', 'gui', 'hand', 'happen', 'hard', 'have', 'heard', 'help', 'high', 'home', 'hope', 'human', 'idea', 'import', 'includ', 'info', 'inform', 'interest', 'internet', 'isn', 'issu', 'john', 'kei', 'kill', 'kind', 'know', 'larg', 'law', 'left', 'let', 'life', 'like', 'line', 'list', 'littl', 'live', 'local', 'long', 'look', 'lot', 'love', 'machin', 'mail', 'major', 'make', 'man', 'manag', 'mark', 'matter', 'mayb', 'mean', 'mention', 'messag', 'mind', 'nation', 'need', 'net', 'new', 'non', 'note', 'number', 'old', 'open', 'opinion', 'order', 'origin', 'peopl', 'person', 'phone', 'place', 'plai', 'point', 'posit', 'possibl', 'post', 'power', 'pretti', 'price', 'probabl', 'problem', 'program', 'provid', 'public', 'question', 'read', 'real', 'reason', 'recent', 'refer', 'rememb', 'repli', 'report', 'requir', 'research', 'respons', 'result', 'right', 'run', 'sai', 'said', 'sale', 'second', 'seen', 'send', 'set', 'small', 'softwar', 'sound', 'sourc', 'space', 'standard', 'start', 'state', 'stuff', 'suggest', 'support', 'sure', 'system', 'take', 'talk', 'team', 'tell', 'thank', 'thing', 'think', 'thought', 'time', 'todai', 'tri', 'true', 'try', 'turn', 'type', 'understand', 'univers', 'us', 'usual', 'version', 'view', 'wai', 'want', 'week', 'win', 'window', 'won', 'wonder', 'word', 'work', 'world', 'write', 'wrong', 'wrote', 'ye', 'year']\n",
            "['abl', 'accept', 'actual', 'address', 'advanc', 'ago', 'agre', 'allow', 'american', 'answer', 'anybodi', 'appreci', 'apr', 'area', 'articl', 'ask', 'assum', 'avail', 'awai', 'bad', 'base', 'believ', 'best', 'better', 'big', 'bit', 'book', 'bui', 'call', 'car', 'card', 'care', 'case', 'caus', 'chang', 'check', 'chip', 'christian', 'claim', 'close', 'com', 'come', 'complet', 'consid', 'control', 'correct', 'cost', 'cours', 'current', 'dai', 'data', 'david', 'deal', 'design', 'differ', 'discuss', 'drive', 'edu', 'effect', 'email', 'end', 'engin', 'exampl', 'exist', 'expect', 'experi', 'fact', 'far', 'fax', 'feel', 'file', 'final', 'follow', 'forc', 'free', 'game', 'gener', 'get', 'given', 'go', 'god', 'good', 'got', 'govern', 'great', 'group', 'guess', 'gui', 'hand', 'happen', 'hard', 'have', 'heard', 'help', 'high', 'home', 'hope', 'human', 'idea', 'import', 'includ', 'info', 'inform', 'interest', 'internet', 'isn', 'issu', 'john', 'kei', 'kill', 'kind', 'know', 'larg', 'law', 'left', 'let', 'life', 'like', 'line', 'list', 'littl', 'live', 'local', 'long', 'look', 'lot', 'love', 'machin', 'mail', 'major', 'make', 'man', 'manag', 'mark', 'matter', 'mayb', 'mean', 'mention', 'messag', 'mind', 'nation', 'need', 'net', 'new', 'non', 'note', 'number', 'old', 'open', 'opinion', 'order', 'origin', 'peopl', 'person', 'phone', 'place', 'plai', 'point', 'posit', 'possibl', 'post', 'power', 'pretti', 'price', 'probabl', 'problem', 'program', 'provid', 'public', 'question', 'read', 'real', 'reason', 'recent', 'refer', 'rememb', 'repli', 'report', 'requir', 'research', 'respons', 'result', 'right', 'run', 'sai', 'said', 'sale', 'second', 'seen', 'send', 'set', 'small', 'softwar', 'sound', 'sourc', 'space', 'standard', 'start', 'state', 'stuff', 'suggest', 'support', 'sure', 'system', 'take', 'talk', 'team', 'tell', 'thank', 'thing', 'think', 'thought', 'time', 'todai', 'tri', 'true', 'try', 'turn', 'type', 'understand', 'univers', 'us', 'usual', 'version', 'view', 'wai', 'want', 'week', 'win', 'window', 'won', 'wonder', 'word', 'work', 'world', 'write', 'wrong', 'wrote', 'ye', 'year']\n",
            "['abl', 'accept', 'actual', 'address', 'advanc', 'ago', 'agre', 'allow', 'american', 'answer', 'anybodi', 'appreci', 'apr', 'area', 'articl', 'ask', 'assum', 'avail', 'awai', 'bad', 'base', 'believ', 'best', 'better', 'big', 'bit', 'book', 'bui', 'call', 'car', 'card', 'care', 'case', 'caus', 'chang', 'check', 'chip', 'christian', 'claim', 'close', 'com', 'come', 'complet', 'consid', 'control', 'correct', 'cost', 'cours', 'current', 'dai', 'data', 'david', 'deal', 'design', 'differ', 'discuss', 'drive', 'edu', 'effect', 'email', 'end', 'engin', 'exampl', 'exist', 'expect', 'experi', 'fact', 'far', 'fax', 'feel', 'file', 'final', 'follow', 'forc', 'free', 'game', 'gener', 'get', 'given', 'go', 'god', 'good', 'got', 'govern', 'great', 'group', 'guess', 'gui', 'hand', 'happen', 'hard', 'have', 'heard', 'help', 'high', 'home', 'hope', 'human', 'idea', 'import', 'includ', 'info', 'inform', 'interest', 'internet', 'isn', 'issu', 'john', 'kei', 'kill', 'kind', 'know', 'larg', 'law', 'left', 'let', 'life', 'like', 'line', 'list', 'littl', 'live', 'local', 'long', 'look', 'lot', 'love', 'machin', 'mail', 'major', 'make', 'man', 'manag', 'mark', 'matter', 'mayb', 'mean', 'mention', 'messag', 'mind', 'nation', 'need', 'net', 'new', 'non', 'note', 'number', 'old', 'open', 'opinion', 'order', 'origin', 'peopl', 'person', 'phone', 'place', 'plai', 'point', 'posit', 'possibl', 'post', 'power', 'pretti', 'price', 'probabl', 'problem', 'program', 'provid', 'public', 'question', 'read', 'real', 'reason', 'recent', 'refer', 'rememb', 'repli', 'report', 'requir', 'research', 'respons', 'result', 'right', 'run', 'sai', 'said', 'sale', 'second', 'seen', 'send', 'set', 'small', 'softwar', 'sound', 'sourc', 'space', 'standard', 'start', 'state', 'stuff', 'suggest', 'support', 'sure', 'system', 'take', 'talk', 'team', 'tell', 'thank', 'thing', 'think', 'thought', 'time', 'todai', 'tri', 'true', 'try', 'turn', 'type', 'understand', 'univers', 'us', 'usual', 'version', 'view', 'wai', 'want', 'week', 'win', 'window', 'won', 'wonder', 'word', 'work', 'world', 'write', 'wrong', 'wrote', 'ye', 'year']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jD71RWm0imht",
        "outputId": "edca47d5-6d7f-4f5c-eedd-315cc4315229"
      },
      "source": [
        "type(corpus_sk_rel)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "scipy.sparse.csr.csr_matrix"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITmbCEpJjEe-",
        "outputId": "f6fe743c-c956-4d93-ed24-50ebea6c77e1"
      },
      "source": [
        "corpus_sk_bin.toarray()[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u436Vvs5wv0M",
        "outputId": "27d1c92e-29b0-4a7d-c50d-ce3758b80def"
      },
      "source": [
        "# Put the frequencies of the first document in a data frame for the first text in the corpus\n",
        "df_1=pd.DataFrame({'keys':vec_tf.get_feature_names(), 'bin': corpus_sk_bin.toarray()[0],'abs':corpus_sk_abs.toarray()[0],'rel': corpus_sk_rel.toarray()[0],'tf': corpus_sk_tf.toarray()[0]})\n",
        "\n",
        "# Show only those with existing words\n",
        "df_1=df_1[df_1.bin>0]\n",
        "#print(df_1[df_1.rel>0])\n",
        "print(df_1)\n",
        "df_1.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       keys  bin  abs       rel        tf\n",
            "28     call    1    1  0.058824  0.149013\n",
            "29      car    1    5  0.294118  0.850820\n",
            "49      dai    1    1  0.058824  0.140095\n",
            "61    engin    1    1  0.058824  0.171939\n",
            "101    info    1    1  0.058824  0.173232\n",
            "111    know    1    1  0.058824  0.097346\n",
            "124    look    1    2  0.117647  0.236706\n",
            "128    mail    1    1  0.058824  0.139212\n",
            "191   small    1    1  0.058824  0.176748\n",
            "208   thank    1    1  0.058824  0.121997\n",
            "231  wonder    1    1  0.058824  0.169843\n",
            "239    year    1    1  0.058824  0.121843\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPwh5HQppvY2",
        "outputId": "60b3e69e-6998-4ca8-8cb2-7461c6faaa63"
      },
      "source": [
        "# Number of times car appears in all documents\n",
        "sum(corpus_sk_bin.toarray()[:,29])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "697"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9y8Z6JgwpbEF",
        "outputId": "7d96b0cf-5776-442c-ed30-4609ebcae574"
      },
      "source": [
        "# idf of car\n",
        "import numpy as np\n",
        "np.log(11314/697)+1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.7870107651425773"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7acFgu3mHNE",
        "outputId": "2cefe3bf-da15-4891-bdcf-52481f414e22"
      },
      "source": [
        "# model output\n",
        "vec_tf.idf_[29]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.7870107651425773"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0r9cyGeczIhF",
        "outputId": "7072e2e4-e826-4b59-aef8-4654e0d8a1ca"
      },
      "source": [
        "# tfidf weights are normalised\n",
        "sum(corpus_sk_tf.toarray()[0,:]**2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9999999999999997"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5C5rXE2zUvS"
      },
      "source": [
        "nor=math.sqrt(sum((corpus_sk_abs.toarray()[0,:]*vec_tf.idf_)**2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "828fsJBD1X5s",
        "outputId": "c72c01ef-a87e-4a4c-bda3-72da3ba5cf9d"
      },
      "source": [
        "nor"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22.255063672543734"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "leF46Fk0nW9k",
        "outputId": "fa2091f0-4e56-4817-baa0-879bc3306463"
      },
      "source": [
        "corpus_sk_abs.toarray()[0,29]*vec_tf.idf_[29]/nor"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8508200247961197"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tPtvaEAwv0M",
        "outputId": "464b3814-fa81-437a-f1c3-2f89f69dbe73"
      },
      "source": [
        "print(df_1.sort_values(by=['tf'], ascending=False)[0:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       keys  bin  abs       rel        tf\n",
            "29      car    1    5  0.294118  0.850820\n",
            "124    look    1    2  0.117647  0.236706\n",
            "191   small    1    1  0.058824  0.176748\n",
            "101    info    1    1  0.058824  0.173232\n",
            "61    engin    1    1  0.058824  0.171939\n",
            "231  wonder    1    1  0.058824  0.169843\n",
            "28     call    1    1  0.058824  0.149013\n",
            "49      dai    1    1  0.058824  0.140095\n",
            "128    mail    1    1  0.058824  0.139212\n",
            "208   thank    1    1  0.058824  0.121997\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SrKSlYS4wv0M",
        "outputId": "57819136-5856-4bfd-f968-023fec00b86f"
      },
      "source": [
        "print(df_1.sort_values(by=['abs'], ascending=False)[0:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      keys  bin  abs       rel        tf\n",
            "29     car    1    5  0.294118  0.850820\n",
            "124   look    1    2  0.117647  0.236706\n",
            "28    call    1    1  0.058824  0.149013\n",
            "49     dai    1    1  0.058824  0.140095\n",
            "61   engin    1    1  0.058824  0.171939\n",
            "101   info    1    1  0.058824  0.173232\n",
            "111   know    1    1  0.058824  0.097346\n",
            "128   mail    1    1  0.058824  0.139212\n",
            "191  small    1    1  0.058824  0.176748\n",
            "208  thank    1    1  0.058824  0.121997\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbIdeRaswv0N"
      },
      "source": [
        "# 2. Bag-of-words with gensim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ce1doHWQwv0N"
      },
      "source": [
        "As opposed to sklearn, gensim requires the data to be already split into tokens."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxzhQZ62wv0N",
        "outputId": "a89c2e93-25bc-4ba9-9610-7250aacb9f1e"
      },
      "source": [
        "corpus_gen=[doc.split() for doc in data_stem]\n",
        "corpus_gen[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['car',\n",
              " 'wonder',\n",
              " 'enlighten',\n",
              " 'car',\n",
              " 'saw',\n",
              " 'dai',\n",
              " 'door',\n",
              " 'sport',\n",
              " 'car',\n",
              " 'look',\n",
              " 'late',\n",
              " 'earli',\n",
              " 'call',\n",
              " 'bricklin',\n",
              " 'door',\n",
              " 'small',\n",
              " 'addit',\n",
              " 'bumper',\n",
              " 'separ',\n",
              " 'rest',\n",
              " 'bodi',\n",
              " 'know',\n",
              " 'tellm',\n",
              " 'model',\n",
              " 'engin',\n",
              " 'spec',\n",
              " 'year',\n",
              " 'product',\n",
              " 'car',\n",
              " 'histori',\n",
              " 'info',\n",
              " 'funki',\n",
              " 'look',\n",
              " 'car',\n",
              " 'mail',\n",
              " 'thank']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrMaA0rHwv0N"
      },
      "source": [
        "Gensim assigns to each token (word) found in the data a unique id. In this way, it is possible to use those ids instead of the words for all operations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGn44IEhwv0O",
        "outputId": "30282784-7924-490d-b7bd-c1b8e969b76c"
      },
      "source": [
        "# Create a gensim dictionary \n",
        "id2word=Dictionary(corpus_gen)\n",
        "\n",
        "# Remove common and rare words\n",
        "id2word.filter_extremes(no_below=566, no_above=0.95)\n",
        "                        \n",
        "# Show the tokens and their ids\n",
        "print(id2word.token2id)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'call': 0, 'car': 1, 'dai': 2, 'engin': 3, 'info': 4, 'know': 5, 'look': 6, 'mail': 7, 'small': 8, 'thank': 9, 'wonder': 10, 'year': 11, 'answer': 12, 'base': 13, 'card': 14, 'edu': 15, 'experi': 16, 'final': 17, 'gui': 18, 'messag': 19, 'number': 20, 'report': 21, 'send': 22, 'actual': 23, 'advanc': 24, 'anybodi': 25, 'better': 26, 'bit': 27, 'email': 28, 'expect': 29, 'feel': 30, 'good': 31, 'got': 32, 'great': 33, 'heard': 34, 'help': 35, 'life': 36, 'like': 37, 'line': 38, 'machin': 39, 'mayb': 40, 'new': 41, 'opinion': 42, 'peopl': 43, 'plai': 44, 'post': 45, 'price': 46, 'probabl': 47, 'question': 48, 'read': 49, 'real': 50, 'recent': 51, 'start': 52, 'take': 53, 'time': 54, 'us': 55, 'wai': 56, 'address': 57, 'articl': 58, 'chip': 59, 'com': 60, 'far': 61, 'inform': 62, 'person': 63, 'phone': 64, 'point': 65, 'pretti': 66, 'requir': 67, 'stuff': 68, 'system': 69, 'thing': 70, 'write': 71, 'wrote': 72, 'check': 73, 'mean': 74, 'possibl': 75, 'right': 76, 'set': 77, 'softwar': 78, 'tell': 79, 'understand': 80, 'world': 81, 'ye': 82, 'agre': 83, 'allow': 84, 'apr': 85, 'believ': 86, 'come': 87, 'consid': 88, 'control': 89, 'cost': 90, 'cours': 91, 'exist': 92, 'follow': 93, 'given': 94, 'govern': 95, 'hand': 96, 'hard': 97, 'hope': 98, 'idea': 99, 'john': 100, 'kill': 101, 'make': 102, 'need': 103, 'non': 104, 'power': 105, 'reason': 106, 'result': 107, 'sai': 108, 'second': 109, 'state': 110, 'support': 111, 'todai': 112, 'file': 113, 'sure': 114, 'thought': 115, 'try': 116, 'accept': 117, 'avail': 118, 'correct': 119, 'data': 120, 'fact': 121, 'go': 122, 'list': 123, 'long': 124, 'love': 125, 'note': 126, 'problem': 127, 'refer': 128, 'said': 129, 'standard': 130, 'think': 131, 'true': 132, 'version': 133, 'appreci': 134, 'chang': 135, 'win': 136, 'bui': 137, 'design': 138, 'mention': 139, 'usual': 140, 'work': 141, 'wrong': 142, 'run': 143, 'want': 144, 'assum': 145, 'case': 146, 'christian': 147, 'david': 148, 'differ': 149, 'end': 150, 'exampl': 151, 'get': 152, 'god': 153, 'guess': 154, 'human': 155, 'kind': 156, 'littl': 157, 'live': 158, 'man': 159, 'mind': 160, 'type': 161, 'current': 162, 'forc': 163, 'kei': 164, 'let': 165, 'major': 166, 'manag': 167, 'mark': 168, 'place': 169, 'provid': 170, 'sourc': 171, 'space': 172, 'team': 173, 'ask': 174, 'high': 175, 'includ': 176, 'old': 177, 'repli': 178, 'sale': 179, 'sound': 180, 'caus': 181, 'gener': 182, 'group': 183, 'happen': 184, 'origin': 185, 'abl': 186, 'big': 187, 'complet': 188, 'deal': 189, 'import': 190, 'program': 191, 'won': 192, 'word': 193, 'ago': 194, 'awai': 195, 'best': 196, 'book': 197, 'care': 198, 'claim': 199, 'close': 200, 'drive': 201, 'interest': 202, 'law': 203, 'rememb': 204, 'respons': 205, 'turn': 206, 'univers': 207, 'view': 208, 'seen': 209, 'matter': 210, 'tri': 211, 'window': 212, 'order': 213, 'fax': 214, 'free': 215, 'left': 216, 'isn': 217, 'game': 218, 'lot': 219, 'local': 220, 'larg': 221, 'week': 222, 'effect': 223, 'public': 224, 'have': 225, 'american': 226, 'issu': 227, 'open': 228, 'talk': 229, 'home': 230, 'bad': 231, 'net': 232, 'posit': 233, 'area': 234, 'nation': 235, 'research': 236, 'discuss': 237, 'suggest': 238, 'internet': 239}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-MsXNbYwv0O",
        "outputId": "0b482553-4dd1-4b8c-a2ce-cb7e9dbcd78f"
      },
      "source": [
        "len(id2word.token2id.keys())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "240"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 193
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqd0-eFXwv0O",
        "outputId": "4466a6ec-38cf-4a46-df2c-07cab2d825d4"
      },
      "source": [
        "# Print all features\n",
        "print(id2word.token2id.keys())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['call', 'car', 'dai', 'engin', 'info', 'know', 'look', 'mail', 'small', 'thank', 'wonder', 'year', 'answer', 'base', 'card', 'edu', 'experi', 'final', 'gui', 'messag', 'number', 'report', 'send', 'actual', 'advanc', 'anybodi', 'better', 'bit', 'email', 'expect', 'feel', 'good', 'got', 'great', 'heard', 'help', 'life', 'like', 'line', 'machin', 'mayb', 'new', 'opinion', 'peopl', 'plai', 'post', 'price', 'probabl', 'question', 'read', 'real', 'recent', 'start', 'take', 'time', 'us', 'wai', 'address', 'articl', 'chip', 'com', 'far', 'inform', 'person', 'phone', 'point', 'pretti', 'requir', 'stuff', 'system', 'thing', 'write', 'wrote', 'check', 'mean', 'possibl', 'right', 'set', 'softwar', 'tell', 'understand', 'world', 'ye', 'agre', 'allow', 'apr', 'believ', 'come', 'consid', 'control', 'cost', 'cours', 'exist', 'follow', 'given', 'govern', 'hand', 'hard', 'hope', 'idea', 'john', 'kill', 'make', 'need', 'non', 'power', 'reason', 'result', 'sai', 'second', 'state', 'support', 'todai', 'file', 'sure', 'thought', 'try', 'accept', 'avail', 'correct', 'data', 'fact', 'go', 'list', 'long', 'love', 'note', 'problem', 'refer', 'said', 'standard', 'think', 'true', 'version', 'appreci', 'chang', 'win', 'bui', 'design', 'mention', 'usual', 'work', 'wrong', 'run', 'want', 'assum', 'case', 'christian', 'david', 'differ', 'end', 'exampl', 'get', 'god', 'guess', 'human', 'kind', 'littl', 'live', 'man', 'mind', 'type', 'current', 'forc', 'kei', 'let', 'major', 'manag', 'mark', 'place', 'provid', 'sourc', 'space', 'team', 'ask', 'high', 'includ', 'old', 'repli', 'sale', 'sound', 'caus', 'gener', 'group', 'happen', 'origin', 'abl', 'big', 'complet', 'deal', 'import', 'program', 'won', 'word', 'ago', 'awai', 'best', 'book', 'care', 'claim', 'close', 'drive', 'interest', 'law', 'rememb', 'respons', 'turn', 'univers', 'view', 'seen', 'matter', 'tri', 'window', 'order', 'fax', 'free', 'left', 'isn', 'game', 'lot', 'local', 'larg', 'week', 'effect', 'public', 'have', 'american', 'issu', 'open', 'talk', 'home', 'bad', 'net', 'posit', 'area', 'nation', 'research', 'discuss', 'suggest', 'internet'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Dz9CQwHwv0O",
        "outputId": "b96e2612-d05b-4bb1-de8c-76eb23418ee6"
      },
      "source": [
        "# Show how many times tokes appear in all documents\n",
        "print(id2word.dfs) #car appears 697 times"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{1: 697, 10: 702, 2: 1361, 6: 2208, 0: 1116, 8: 602, 5: 3524, 3: 670, 11: 2043, 4: 651, 7: 1388, 9: 2036, 17: 576, 21: 601, 20: 1174, 16: 627, 22: 740, 19: 819, 14: 703, 13: 895, 12: 767, 18: 595, 15: 5726, 48: 1775, 52: 1229, 36: 725, 56: 2218, 41: 2924, 39: 609, 27: 1002, 40: 806, 25: 567, 29: 581, 34: 726, 46: 613, 38: 990, 37: 3848, 51: 629, 47: 1116, 32: 1223, 30: 705, 26: 1215, 33: 965, 31: 2334, 42: 1059, 43: 2549, 55: 2514, 53: 638, 50: 928, 44: 769, 23: 1095, 35: 1621, 24: 650, 28: 775, 45: 1800, 49: 1488, 54: 2822, 72: 808, 71: 6081, 58: 4988, 59: 582, 61: 958, 68: 571, 66: 651, 67: 729, 65: 1570, 57: 632, 64: 716, 62: 1112, 60: 3759, 69: 599, 70: 2070, 63: 1244, 81: 1023, 82: 772, 74: 1484, 80: 729, 78: 824, 73: 650, 76: 1852, 77: 990, 75: 1206, 79: 1210, 109: 865, 99: 953, 85: 2841, 100: 743, 105: 963, 102: 1108, 90: 587, 103: 2175, 89: 926, 95: 846, 107: 686, 104: 748, 92: 829, 110: 1354, 87: 1668, 86: 1434, 97: 847, 111: 964, 83: 662, 96: 787, 98: 771, 91: 1025, 108: 1287, 93: 1229, 101: 663, 106: 1298, 84: 738, 94: 674, 88: 970, 112: 706, 115: 940, 114: 1398, 116: 1621, 113: 820, 117: 665, 124: 1145, 127: 1832, 125: 573, 123: 766, 130: 671, 133: 589, 126: 811, 120: 633, 119: 576, 121: 1137, 118: 859, 129: 1302, 131: 2950, 132: 876, 122: 1322, 128: 684, 136: 641, 135: 934, 134: 678, 138: 577, 141: 2320, 142: 824, 140: 574, 139: 642, 137: 719, 143: 1381, 144: 2347, 148: 785, 150: 994, 149: 1341, 153: 846, 146: 1231, 159: 741, 147: 692, 160: 629, 158: 998, 151: 783, 156: 779, 157: 1111, 155: 582, 154: 590, 145: 639, 161: 660, 152: 1063, 172: 610, 168: 573, 165: 1326, 162: 787, 173: 582, 164: 635, 170: 761, 167: 568, 163: 580, 171: 662, 169: 1029, 166: 646, 179: 587, 175: 848, 180: 698, 176: 1124, 174: 1192, 177: 881, 178: 825, 183: 954, 184: 985, 185: 1004, 181: 772, 182: 1149, 191: 994, 187: 747, 193: 851, 188: 616, 186: 824, 190: 623, 192: 707, 189: 566, 200: 625, 201: 898, 207: 1287, 204: 722, 206: 740, 199: 754, 203: 794, 195: 743, 194: 685, 202: 1130, 197: 655, 205: 762, 208: 630, 196: 1014, 198: 637, 209: 788, 212: 1021, 211: 568, 210: 628, 213: 824, 215: 701, 214: 603, 216: 642, 217: 801, 218: 778, 219: 1176, 220: 578, 221: 643, 222: 659, 223: 708, 224: 743, 225: 842, 226: 614, 229: 930, 228: 602, 227: 723, 230: 647, 231: 793, 232: 707, 233: 570, 234: 628, 235: 679, 236: 611, 237: 631, 238: 767, 239: 701}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBbh-csAkw3L"
      },
      "source": [
        "# Absolute frequencies\n",
        "corpus_gen_abs=[id2word.doc2bow(doc) for doc in corpus_gen]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AqobrkW7kycc",
        "outputId": "ddf06dfb-a175-453b-a9dd-2efbb7e8066d"
      },
      "source": [
        "corpus_gen_abs[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, 1),\n",
              " (1, 5),\n",
              " (2, 1),\n",
              " (3, 1),\n",
              " (4, 1),\n",
              " (5, 1),\n",
              " (6, 2),\n",
              " (7, 1),\n",
              " (8, 1),\n",
              " (9, 1),\n",
              " (10, 1),\n",
              " (11, 1)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WW52ejwmwv0P"
      },
      "source": [
        "# Relative frequencies\n",
        "corpus_gen_rel=[[(token[0],(token[1]/sum(n for _, n in doc))) for token in doc] for doc in corpus_gen_abs]\n",
        "\n",
        "                  \n",
        "# Binary frequencies\n",
        "corpus_gen_bin=[[(token[0],1) for token in doc] for doc in corpus_gen_abs]\n",
        "\n",
        "# Tfidf frequencies\n",
        "tfidf=TfidfModel(dictionary=id2word, normalize=True)\n",
        "\n",
        "# Get sklearn\n",
        "\n",
        "#from gensim.models.tfidfmodel import df2idf\n",
        "#from math import e\n",
        "#def d2f(docfreq, totaldocs):\n",
        "#    return df2idf(docfreq, totaldocs, log_base=e, add=1.0)\n",
        "#tfidf=TfidfModel(dictionary=id2word, normalize=True, wglobal=d2f)\n",
        "\n",
        "corpus_gen_tf=[tfidf[id2word.doc2bow(doc)] for doc in corpus_gen]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGDVsYYLr1Y2",
        "outputId": "225db1fc-fc34-4b2b-b227-83da280d21ef"
      },
      "source": [
        "# idf term for car (id=1)\n",
        "math.log2(11314/697)\n",
        "np.log(11314/697)+1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.020806609775351"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 199
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RPpLndws37e",
        "outputId": "0138b4ab-c61f-4262-cbd0-3fbbfd659ddd"
      },
      "source": [
        "tfidf.idfs[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.020806609775351"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 200
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lWN6dbtB17Od",
        "outputId": "5bd886b9-0374-4624-d5d0-ff4fd6171481"
      },
      "source": [
        "len(corpus_gen_tf[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 201
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9xfv8G71qc9",
        "outputId": "780663ea-cd6a-4dff-a639-bc2cb441bb09"
      },
      "source": [
        "sum([corpus_gen_tf[0][i][1]**2 for i in range(len(corpus_gen_tf[0]))])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0000000000000004"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 202
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PLJ3YCf0xmX"
      },
      "source": [
        "# normalisation\n",
        "nor2=math.sqrt(sum([(corpus_gen_abs[0][i][1]*tfidf.idfs[i])**2 for i in range(len(corpus_gen_abs[0]))]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWrHmfvV1S8s",
        "outputId": "a85fb460-10fd-47c2-daf9-ddaae48ab6af"
      },
      "source": [
        "nor2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23.210110013268068"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 204
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rgPdKuWtMzK",
        "outputId": "601e6b93-e108-4e7b-a9b8-fd461c18ef21"
      },
      "source": [
        "(corpus_gen_abs[0][1][1]*tfidf.idfs[1])/nor2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8661756897052311"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 205
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WxLQfpNFwv0P",
        "outputId": "3d29455f-3ff2-4806-e27e-45b096afa69f"
      },
      "source": [
        "print('binary')\n",
        "print(corpus_gen_bin[0])\n",
        "print(' ')\n",
        "print('absolute')\n",
        "print(corpus_gen_abs[0])\n",
        "print(' ')\n",
        "print('relative')\n",
        "print(corpus_gen_rel[0])\n",
        "print(' ')\n",
        "print('tf-idf')\n",
        "print(corpus_gen_tf[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "binary\n",
            "[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1)]\n",
            " \n",
            "absolute\n",
            "[(0, 1), (1, 5), (2, 1), (3, 1), (4, 1), (5, 1), (6, 2), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1)]\n",
            " \n",
            "relative\n",
            "[(0, 0.058823529411764705), (1, 0.29411764705882354), (2, 0.058823529411764705), (3, 0.058823529411764705), (4, 0.058823529411764705), (5, 0.058823529411764705), (6, 0.11764705882352941), (7, 0.058823529411764705), (8, 0.058823529411764705), (9, 0.058823529411764705), (10, 0.058823529411764705), (11, 0.058823529411764705)]\n",
            " \n",
            "tf-idf\n",
            "[(0, 0.14397605792925167), (1, 0.8661756897052311), (2, 0.1316396218024463), (3, 0.17569085919746014), (4, 0.17747902617106662), (5, 0.07250388928623666), (6, 0.20312674067620154), (7, 0.13041858058126876), (8, 0.18234302967391078), (9, 0.1066043895592759), (10, 0.17279083266070747), (11, 0.10639104965460928)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ckbDr4UdkJZ",
        "outputId": "d0490e21-b5be-474d-d3b6-418ccde6fa87"
      },
      "source": [
        "len(corpus_gen_abs[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFgTYQfzwv0P"
      },
      "source": [
        "k=[list(id2word.token2id.keys())[i] for i in range(len(corpus_gen_bin[0]))]\n",
        "tf=[corpus_gen_tf[0][i][1] for i in range(len(corpus_gen_bin[0]))]\n",
        "rel=[corpus_gen_rel[0][i][1] for i in range(len(corpus_gen_bin[0]))]\n",
        "ab=[corpus_gen_abs[0][i][1] for i in range(len(corpus_gen_abs[0]))]\n",
        "bi=[corpus_gen_bin[0][i][1] for i in range(len(corpus_gen_bin[0]))]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "laQneNaKwv0Q",
        "outputId": "70bee35b-e7a7-4a08-8e79-c8a8154b85d8"
      },
      "source": [
        "# Put the frequencies in a data farme for the first text in the corpus\n",
        "df_12=pd.DataFrame({'keys':k, 'bin': bi,'abs':ab,'rel':rel,'tf': tf})\n",
        "print(df_12)\n",
        "df_12.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      keys  bin  abs       rel        tf\n",
            "0     call    1    1  0.058824  0.143976\n",
            "1      car    1    5  0.294118  0.866176\n",
            "2      dai    1    1  0.058824  0.131640\n",
            "3    engin    1    1  0.058824  0.175691\n",
            "4     info    1    1  0.058824  0.177479\n",
            "5     know    1    1  0.058824  0.072504\n",
            "6     look    1    2  0.117647  0.203127\n",
            "7     mail    1    1  0.058824  0.130419\n",
            "8    small    1    1  0.058824  0.182343\n",
            "9    thank    1    1  0.058824  0.106604\n",
            "10  wonder    1    1  0.058824  0.172791\n",
            "11    year    1    1  0.058824  0.106391\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "7Ci2x-9Twv0Q",
        "outputId": "8d777148-1625-4b33-cfb9-7da6e6794ed1"
      },
      "source": [
        "df_merge=pd.merge(df_12, df_1, on='keys')\n",
        "df_merge"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>keys</th>\n",
              "      <th>bin_x</th>\n",
              "      <th>abs_x</th>\n",
              "      <th>rel_x</th>\n",
              "      <th>tf_x</th>\n",
              "      <th>bin_y</th>\n",
              "      <th>abs_y</th>\n",
              "      <th>rel_y</th>\n",
              "      <th>tf_y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>call</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.058824</td>\n",
              "      <td>0.143976</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.058824</td>\n",
              "      <td>0.149013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>car</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0.294118</td>\n",
              "      <td>0.866176</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0.294118</td>\n",
              "      <td>0.850820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>dai</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.058824</td>\n",
              "      <td>0.131640</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.058824</td>\n",
              "      <td>0.140095</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>engin</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.058824</td>\n",
              "      <td>0.175691</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.058824</td>\n",
              "      <td>0.171939</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>info</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.058824</td>\n",
              "      <td>0.177479</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.058824</td>\n",
              "      <td>0.173232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>know</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.058824</td>\n",
              "      <td>0.072504</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.058824</td>\n",
              "      <td>0.097346</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>look</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.117647</td>\n",
              "      <td>0.203127</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.117647</td>\n",
              "      <td>0.236706</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>mail</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.058824</td>\n",
              "      <td>0.130419</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.058824</td>\n",
              "      <td>0.139212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>small</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.058824</td>\n",
              "      <td>0.182343</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.058824</td>\n",
              "      <td>0.176748</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>thank</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.058824</td>\n",
              "      <td>0.106604</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.058824</td>\n",
              "      <td>0.121997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>wonder</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.058824</td>\n",
              "      <td>0.172791</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.058824</td>\n",
              "      <td>0.169843</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>year</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.058824</td>\n",
              "      <td>0.106391</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.058824</td>\n",
              "      <td>0.121843</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      keys  bin_x  abs_x     rel_x      tf_x  bin_y  abs_y     rel_y      tf_y\n",
              "0     call      1      1  0.058824  0.143976      1      1  0.058824  0.149013\n",
              "1      car      1      5  0.294118  0.866176      1      5  0.294118  0.850820\n",
              "2      dai      1      1  0.058824  0.131640      1      1  0.058824  0.140095\n",
              "3    engin      1      1  0.058824  0.175691      1      1  0.058824  0.171939\n",
              "4     info      1      1  0.058824  0.177479      1      1  0.058824  0.173232\n",
              "5     know      1      1  0.058824  0.072504      1      1  0.058824  0.097346\n",
              "6     look      1      2  0.117647  0.203127      1      2  0.117647  0.236706\n",
              "7     mail      1      1  0.058824  0.130419      1      1  0.058824  0.139212\n",
              "8    small      1      1  0.058824  0.182343      1      1  0.058824  0.176748\n",
              "9    thank      1      1  0.058824  0.106604      1      1  0.058824  0.121997\n",
              "10  wonder      1      1  0.058824  0.172791      1      1  0.058824  0.169843\n",
              "11    year      1      1  0.058824  0.106391      1      1  0.058824  0.121843"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4bldR09wv0Q"
      },
      "source": [
        "# 3. Ngrams"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZOWwpo-wv0Q"
      },
      "source": [
        "# Two-gram absolute transformer (min=max=2 words)\n",
        "bigram_vectorizer = CountVectorizer(ngram_range=(2, 2), max_df=0.95, min_df=0.05)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXt4FxBIwv0Q",
        "outputId": "e38df801-c064-4b7a-a983-59d1ce24da08"
      },
      "source": [
        "# Trasform data\n",
        "corpus_sk_bi=bigram_vectorizer.fit_transform(data_stem)\n",
        "print(bigram_vectorizer.get_feature_names())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['articl apr', 'edu write', 'write articl']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iN1kff16wv0R"
      },
      "source": [
        "You can see that there are much less words than for one-grams. The reason is that combination of words come less rarely over all documents than single words. However, if you remove the document frequency filtering, you will get much more words than for one-grams."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "SawSGF9Kwv0R",
        "outputId": "5feed938-60e6-416f-9617-2e8f1cca9325"
      },
      "source": [
        "corpus_sk_bi_df=pd.DataFrame(corpus_sk_bi.toarray(), columns=bigram_vectorizer.get_feature_names())\n",
        "corpus_sk_bi_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>articl apr</th>\n",
              "      <th>edu write</th>\n",
              "      <th>write articl</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   articl apr  edu write  write articl\n",
              "0           0          0             0\n",
              "1           0          0             0\n",
              "2           0          0             0\n",
              "3           0          1             1\n",
              "4           0          0             0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 212
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzmjcE52wv0R",
        "outputId": "c9d6341c-a70d-4029-b99a-fe169beaf815"
      },
      "source": [
        "corpus_sk_bi_df.max()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "articl apr      4\n",
              "edu write       2\n",
              "write articl    4\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 213
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9V48ul4vwv0R"
      },
      "source": [
        "The maximum frequency is 4 which is much less than for one-grams."
      ]
    }
  ]
}