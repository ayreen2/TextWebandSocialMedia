{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "2_Text_Preprocessing.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVCvhTfIJJf0"
      },
      "source": [
        "# Exercise 2. Text Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9AczlUWfwpd6",
        "outputId": "8afb04a7-26bb-4bc4-db91-040ff4ff78b3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZPVKf76JJf5"
      },
      "source": [
        "In this exercise, we will be using the 20-Newsgroups dataset. This version of the dataset contains about 11k newsgroups posts from 20 different topics.\n",
        "\n",
        "We will learn how to apply the following steps:\n",
        "\n",
        "1. Import and examine data\n",
        "2. Remove initial text metadata with regex\n",
        "3. Remove numbers, punctuation, tabs and convert to lower case with gensim\n",
        "4. Stopwords and short words removal\n",
        "5. Stemming and lematization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8pt8XPwpJJf6",
        "outputId": "8f6acd0e-43db-4bc9-e668-bfb522586ce9"
      },
      "source": [
        "# Import packages\n",
        "import pandas as pd\n",
        "import re\n",
        "from gensim.parsing.preprocessing import STOPWORDS, strip_tags, strip_numeric, strip_punctuation, strip_multiple_whitespaces, remove_stopwords, strip_short, stem_text\n",
        "import pickle\n",
        "import en_core_web_sm\n",
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqbibgI_Apwb"
      },
      "source": [
        "from nltk.corpus import stopwords"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NRuxwx9JJf8"
      },
      "source": [
        "# 1. Import and examine data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "p34gaa_tJJf8",
        "outputId": "f7d1e3a0-c252-4dff-f84d-2b03e5d597f8"
      },
      "source": [
        "# Import dataset\n",
        "df = pd.read_json('https://raw.githubusercontent.com/selva86/datasets/master/newsgroups.json')\n",
        "df.head()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>target</th>\n",
              "      <th>target_names</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>From: lerxst@wam.umd.edu (where's my thing)\\nS...</td>\n",
              "      <td>7</td>\n",
              "      <td>rec.autos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>From: guykuo@carson.u.washington.edu (Guy Kuo)...</td>\n",
              "      <td>4</td>\n",
              "      <td>comp.sys.mac.hardware</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>From: twillis@ec.ecn.purdue.edu (Thomas E Will...</td>\n",
              "      <td>4</td>\n",
              "      <td>comp.sys.mac.hardware</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>From: jgreen@amber (Joe Green)\\nSubject: Re: W...</td>\n",
              "      <td>1</td>\n",
              "      <td>comp.graphics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>From: jcm@head-cfa.harvard.edu (Jonathan McDow...</td>\n",
              "      <td>14</td>\n",
              "      <td>sci.space</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             content  ...           target_names\n",
              "0  From: lerxst@wam.umd.edu (where's my thing)\\nS...  ...              rec.autos\n",
              "1  From: guykuo@carson.u.washington.edu (Guy Kuo)...  ...  comp.sys.mac.hardware\n",
              "2  From: twillis@ec.ecn.purdue.edu (Thomas E Will...  ...  comp.sys.mac.hardware\n",
              "3  From: jgreen@amber (Joe Green)\\nSubject: Re: W...  ...          comp.graphics\n",
              "4  From: jcm@head-cfa.harvard.edu (Jonathan McDow...  ...              sci.space\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zSKKAbCIJJf8",
        "outputId": "3ceab071-47cd-429b-d37b-b58b555596b3"
      },
      "source": [
        "# Examine dataset\n",
        "print('Possible tagret values:')\n",
        "print(df.target_names.unique())\n",
        "print(' ')\n",
        "print('Class distribution:')\n",
        "print(df.target_names.value_counts())"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Possible tagret values:\n",
            "['rec.autos' 'comp.sys.mac.hardware' 'comp.graphics' 'sci.space'\n",
            " 'talk.politics.guns' 'sci.med' 'comp.sys.ibm.pc.hardware'\n",
            " 'comp.os.ms-windows.misc' 'rec.motorcycles' 'talk.religion.misc'\n",
            " 'misc.forsale' 'alt.atheism' 'sci.electronics' 'comp.windows.x'\n",
            " 'rec.sport.hockey' 'rec.sport.baseball' 'soc.religion.christian'\n",
            " 'talk.politics.mideast' 'talk.politics.misc' 'sci.crypt']\n",
            " \n",
            "Class distribution:\n",
            "rec.sport.hockey            600\n",
            "soc.religion.christian      599\n",
            "rec.motorcycles             598\n",
            "rec.sport.baseball          597\n",
            "sci.crypt                   595\n",
            "sci.med                     594\n",
            "rec.autos                   594\n",
            "comp.windows.x              593\n",
            "sci.space                   593\n",
            "comp.os.ms-windows.misc     591\n",
            "sci.electronics             591\n",
            "comp.sys.ibm.pc.hardware    590\n",
            "misc.forsale                585\n",
            "comp.graphics               584\n",
            "comp.sys.mac.hardware       578\n",
            "talk.politics.mideast       564\n",
            "talk.politics.guns          546\n",
            "alt.atheism                 480\n",
            "talk.politics.misc          465\n",
            "talk.religion.misc          377\n",
            "Name: target_names, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCGteqesJJf9"
      },
      "source": [
        "*The classes are almost uniformly distributed.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qU-E-1ZlJJf9",
        "outputId": "e390c63e-053b-4bef-ea0c-24fe82bbeae1"
      },
      "source": [
        "# The first entry in the content field\n",
        "print(df.content[0])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "From: lerxst@wam.umd.edu (where's my thing)\n",
            "Subject: WHAT car is this!?\n",
            "Nntp-Posting-Host: rac3.wam.umd.edu\n",
            "Organization: University of Maryland, College Park\n",
            "Lines: 15\n",
            "\n",
            " I was wondering if anyone out there could enlighten me on this car I saw\n",
            "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
            "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
            "the front bumper was separate from the rest of the body. This is \n",
            "all I know. If anyone can tellme a model name, engine specs, years\n",
            "of production, where this car is made, history, or whatever info you\n",
            "have on this funky looking car, please e-mail.\n",
            "\n",
            "Thanks,\n",
            "- IL\n",
            "   ---- brought to you by your neighborhood Lerxst ----\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbbUUYfPJJf-",
        "outputId": "8f62b9d1-b42a-4c12-d757-02563cfb9a1f"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11314, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMhzS3CRJJf-"
      },
      "source": [
        "*The data contains 11314 rows.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-CJmcBZJJf-"
      },
      "source": [
        "# 2. Remove initial text metadata"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIMw4jPDJJf-",
        "outputId": "7fdf029c-b7f2-45b6-a4f6-216f7f47ddcd"
      },
      "source": [
        "# Remove unnecessary headers\n",
        "#(8768|9875|2353)\n",
        "data = [re.sub('(?m)^(From:|Article-I.D.:|Organization:|Lines:|Nntp-Posting-Host:|Distribution:|Reply-To:|X-Newsreader:|Expires:|\\s*-+).*\\n', '', sent, flags=re.I) for sent in df.content]\n",
        "data = [re.sub('(Subject:|Summary:|Keywords:)', '', sent, flags=re.I) for sent in data]\n",
        "\n",
        "#print(df.iloc[10]['content'])\n",
        "print(data[0])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " WHAT car is this!?\n",
            "\n",
            " I was wondering if anyone out there could enlighten me on this car I saw\n",
            "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
            "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
            "the front bumper was separate from the rest of the body. This is \n",
            "all I know. If anyone can tellme a model name, engine specs, years\n",
            "of production, where this car is made, history, or whatever info you\n",
            "have on this funky looking car, please e-mail.\n",
            "\n",
            "Thanks,\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLnjdmT-JJf_"
      },
      "source": [
        "# 3. Remove numbers, punctuation, tabs and convert to lower case with gensim"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MG2zjzvJJJf_",
        "outputId": "680e5568-a70c-492e-cca8-9165ceab0691"
      },
      "source": [
        "# Remove numbers\n",
        "data=[strip_numeric(sent) for sent in data]\n",
        "print(data[0])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " WHAT car is this!?\n",
            "\n",
            " I was wondering if anyone out there could enlighten me on this car I saw\n",
            "the other day. It was a -door sports car, looked to be from the late s/\n",
            "early s. It was called a Bricklin. The doors were really small. In addition,\n",
            "the front bumper was separate from the rest of the body. This is \n",
            "all I know. If anyone can tellme a model name, engine specs, years\n",
            "of production, where this car is made, history, or whatever info you\n",
            "have on this funky looking car, please e-mail.\n",
            "\n",
            "Thanks,\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBEw3QhEJJf_",
        "outputId": "742d3e44-6406-49bd-d624-01559d8cdd17"
      },
      "source": [
        "# Remove punctuation\n",
        "data=[strip_punctuation(sent) for sent in data]\n",
        "print(data[0])"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " WHAT car is this \n",
            "\n",
            " I was wondering if anyone out there could enlighten me on this car I saw\n",
            "the other day  It was a  door sports car  looked to be from the late s \n",
            "early s  It was called a Bricklin  The doors were really small  In addition \n",
            "the front bumper was separate from the rest of the body  This is \n",
            "all I know  If anyone can tellme a model name  engine specs  years\n",
            "of production  where this car is made  history  or whatever info you\n",
            "have on this funky looking car  please e mail \n",
            "\n",
            "Thanks \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLGucgxjJJgA",
        "outputId": "2848093f-42c6-4f79-feb3-89b56eb32fac"
      },
      "source": [
        "# Remove multiple spaces\n",
        "data=[strip_multiple_whitespaces(sent) for sent in data]\n",
        "print(data[0])"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " WHAT car is this I was wondering if anyone out there could enlighten me on this car I saw the other day It was a door sports car looked to be from the late s early s It was called a Bricklin The doors were really small In addition the front bumper was separate from the rest of the body This is all I know If anyone can tellme a model name engine specs years of production where this car is made history or whatever info you have on this funky looking car please e mail Thanks \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nRFsjDFJJgA",
        "outputId": "59b53c33-fa7d-4063-ea4a-8dc3f3c7dcc0"
      },
      "source": [
        "# Transform all data to lower-case\n",
        "data=[sent.lower() for sent in data]\n",
        "print(data[0])"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " what car is this i was wondering if anyone out there could enlighten me on this car i saw the other day it was a door sports car looked to be from the late s early s it was called a bricklin the doors were really small in addition the front bumper was separate from the rest of the body this is all i know if anyone can tellme a model name engine specs years of production where this car is made history or whatever info you have on this funky looking car please e mail thanks \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGSM9Y7SJJgA"
      },
      "source": [
        "# 4. Stopwords and short words removal "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNJEowkTJJgA"
      },
      "source": [
        "Here we will compare the stopwords in gensim and nltk."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idT5PFQRJJgA"
      },
      "source": [
        "#### Gensim"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNIctUfAJJgB",
        "outputId": "251f37d9-cc51-4d31-8d3d-ea85408cd6c7"
      },
      "source": [
        "all_stopwords = STOPWORDS\n",
        "print(sorted(all_stopwords))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['a', 'about', 'above', 'across', 'after', 'afterwards', 'again', 'against', 'all', 'almost', 'alone', 'along', 'already', 'also', 'although', 'always', 'am', 'among', 'amongst', 'amoungst', 'amount', 'an', 'and', 'another', 'any', 'anyhow', 'anyone', 'anything', 'anyway', 'anywhere', 'are', 'around', 'as', 'at', 'back', 'be', 'became', 'because', 'become', 'becomes', 'becoming', 'been', 'before', 'beforehand', 'behind', 'being', 'below', 'beside', 'besides', 'between', 'beyond', 'bill', 'both', 'bottom', 'but', 'by', 'call', 'can', 'cannot', 'cant', 'co', 'computer', 'con', 'could', 'couldnt', 'cry', 'de', 'describe', 'detail', 'did', 'didn', 'do', 'does', 'doesn', 'doing', 'don', 'done', 'down', 'due', 'during', 'each', 'eg', 'eight', 'either', 'eleven', 'else', 'elsewhere', 'empty', 'enough', 'etc', 'even', 'ever', 'every', 'everyone', 'everything', 'everywhere', 'except', 'few', 'fifteen', 'fify', 'fill', 'find', 'fire', 'first', 'five', 'for', 'former', 'formerly', 'forty', 'found', 'four', 'from', 'front', 'full', 'further', 'get', 'give', 'go', 'had', 'has', 'hasnt', 'have', 'he', 'hence', 'her', 'here', 'hereafter', 'hereby', 'herein', 'hereupon', 'hers', 'herself', 'him', 'himself', 'his', 'how', 'however', 'hundred', 'i', 'ie', 'if', 'in', 'inc', 'indeed', 'interest', 'into', 'is', 'it', 'its', 'itself', 'just', 'keep', 'kg', 'km', 'last', 'latter', 'latterly', 'least', 'less', 'ltd', 'made', 'make', 'many', 'may', 'me', 'meanwhile', 'might', 'mill', 'mine', 'more', 'moreover', 'most', 'mostly', 'move', 'much', 'must', 'my', 'myself', 'name', 'namely', 'neither', 'never', 'nevertheless', 'next', 'nine', 'no', 'nobody', 'none', 'noone', 'nor', 'not', 'nothing', 'now', 'nowhere', 'of', 'off', 'often', 'on', 'once', 'one', 'only', 'onto', 'or', 'other', 'others', 'otherwise', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 'part', 'per', 'perhaps', 'please', 'put', 'quite', 'rather', 're', 'really', 'regarding', 'same', 'say', 'see', 'seem', 'seemed', 'seeming', 'seems', 'serious', 'several', 'she', 'should', 'show', 'side', 'since', 'sincere', 'six', 'sixty', 'so', 'some', 'somehow', 'someone', 'something', 'sometime', 'sometimes', 'somewhere', 'still', 'such', 'system', 'take', 'ten', 'than', 'that', 'the', 'their', 'them', 'themselves', 'then', 'thence', 'there', 'thereafter', 'thereby', 'therefore', 'therein', 'thereupon', 'these', 'they', 'thick', 'thin', 'third', 'this', 'those', 'though', 'three', 'through', 'throughout', 'thru', 'thus', 'to', 'together', 'too', 'top', 'toward', 'towards', 'twelve', 'twenty', 'two', 'un', 'under', 'unless', 'until', 'up', 'upon', 'us', 'used', 'using', 'various', 'very', 'via', 'was', 'we', 'well', 'were', 'what', 'whatever', 'when', 'whence', 'whenever', 'where', 'whereafter', 'whereas', 'whereby', 'wherein', 'whereupon', 'wherever', 'whether', 'which', 'while', 'whither', 'who', 'whoever', 'whole', 'whom', 'whose', 'why', 'will', 'with', 'within', 'without', 'would', 'yet', 'you', 'your', 'yours', 'yourself', 'yourselves']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIXFtan1JJgB"
      },
      "source": [
        "#### NLTK"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ei1zHrFtJJgB",
        "outputId": "ce4c8d9a-74ab-4c9d-ef9b-95fb045ef1de"
      },
      "source": [
        "nltk_stopwords = set(stopwords.words('english'))\n",
        "print(sorted(nltk_stopwords))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an', 'and', 'any', 'are', 'aren', \"aren't\", 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', 'can', 'couldn', \"couldn't\", 'd', 'did', 'didn', \"didn't\", 'do', 'does', 'doesn', \"doesn't\", 'doing', 'don', \"don't\", 'down', 'during', 'each', 'few', 'for', 'from', 'further', 'had', 'hadn', \"hadn't\", 'has', 'hasn', \"hasn't\", 'have', 'haven', \"haven't\", 'having', 'he', 'her', 'here', 'hers', 'herself', 'him', 'himself', 'his', 'how', 'i', 'if', 'in', 'into', 'is', 'isn', \"isn't\", 'it', \"it's\", 'its', 'itself', 'just', 'll', 'm', 'ma', 'me', 'mightn', \"mightn't\", 'more', 'most', 'mustn', \"mustn't\", 'my', 'myself', 'needn', \"needn't\", 'no', 'nor', 'not', 'now', 'o', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 're', 's', 'same', 'shan', \"shan't\", 'she', \"she's\", 'should', \"should've\", 'shouldn', \"shouldn't\", 'so', 'some', 'such', 't', 'than', 'that', \"that'll\", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', 'these', 'they', 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 've', 'very', 'was', 'wasn', \"wasn't\", 'we', 'were', 'weren', \"weren't\", 'what', 'when', 'where', 'which', 'while', 'who', 'whom', 'why', 'will', 'with', 'won', \"won't\", 'wouldn', \"wouldn't\", 'y', 'you', \"you'd\", \"you'll\", \"you're\", \"you've\", 'your', 'yours', 'yourself', 'yourselves']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FhiCukC8JJgB",
        "outputId": "307f3582-40f0-4740-b8a0-817afbc970ff"
      },
      "source": [
        "data=[remove_stopwords(sent) for sent in data]\n",
        "print(data[0])"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "car wondering enlighten car saw day door sports car looked late s early s called bricklin doors small addition bumper separate rest body know tellme model engine specs years production car history info funky looking car e mail thanks\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BETTEN17JJgC",
        "outputId": "3a7b05d2-bc00-4b19-b1b9-bacd8e732d47"
      },
      "source": [
        "data=[strip_short(sent) for sent in data]\n",
        "print(data[0])"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "car wondering enlighten car saw day door sports car looked late early called bricklin doors small addition bumper separate rest body know tellme model engine specs years production car history info funky looking car mail thanks\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9G64KrgJJgC"
      },
      "source": [
        "# 5. Stemming and Lematization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7LTnx_uJJgC",
        "outputId": "44eea46e-1c6f-4014-eefa-74ce536ff57d"
      },
      "source": [
        "data_stem=[stem_text(sent) for sent in data]\n",
        "#data_stem=[strip_short(sent) for sent in data_stem]\n",
        "print(data_stem[0])"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "car wonder enlighten car saw dai door sport car look late earli call bricklin door small addit bumper separ rest bodi know tellm model engin spec year product car histori info funki look car mail thank\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSLzKSPgJJgC",
        "outputId": "9db46f19-94a0-4552-f9e9-6da5e87695e4"
      },
      "source": [
        "# Initialize spacy 'en' model\n",
        "nlp = en_core_web_sm.load()\n",
        "# Parse the sentence using the loaded 'en' model object `nlp`\n",
        "data_lem_base=[nlp(sent) for sent in data]\n",
        "# Extract the lemma for each token and join\n",
        "data_lem=[\" \".join([token.lemma_ for token in sent]) for sent in data_lem_base]\n",
        "print(data_lem[0])"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "car wonder enlighten car see day door sport car look late early call bricklin door small addition bumper separate rest body know tellme model engine specs year production car history info funky looking car mail thank\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yOdQK1bJJgD"
      },
      "source": [
        "# 6. Corpus storage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4F9ajJ0JJgD"
      },
      "source": [
        "IMPORTNANT: store your preprocessed corpus as you don’t want to do this over and over again."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BIVtHcgJJgD"
      },
      "source": [
        "pickle.dump(data_stem, open(\"/content/drive/MyDrive/TWSM_Data/Stemmed.pkl\", \"wb\"))\n",
        "pickle.dump(data_lem, open(\"/content/drive/MyDrive/TWSM_Data/Lemma.pkl\", \"wb\"))"
      ],
      "execution_count": 41,
      "outputs": []
    }
  ]
}